# Build, Train, and Deploy ML Pipelines Using BERT

## Week 1:
[C2_W1_Assignment](https://github.com/curtpond/practical-aws/blob/main/nb/week2/C2_W1_Assignment.ipynb)

[Slides for Week 1](./slides/C2_W1.pdf)
### Objectives
- Apply feature engineering to prepare datasets for training.
- Select feautures and labels, balance the dataset, split the dataset, transform the data.
- Configure, store, and share features using Amazon SageMaker Feature Store.
- Build a multi-class text classification for sentiment analysis BERT model of product reviews.

## Week 2:
[C2_W2_Assignment](https://github.com/curtpond/practical-aws/blob/main/nb/week2/C2_W2_Assignment.ipynb)

[Slides for Week 2](./slides/C2_W2.pdf)
### Objectives
- Train a text classifier using a variant of BERT called RoBERTa.
- Train a custom model with Amazon SageMaker (Bring Your Own Script)
- Configure dataset & evaluation metrics
- Configure hyperparameters
- Providing training script
- Fit the model
- Debug and profile models


